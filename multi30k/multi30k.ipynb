{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install -U torchtext\n","!python -m spacy download de\n","!python -m spacy download en\n","!mkdir -p results/"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import sys, os, time, math\n","\n","# Add utility_scripts in the current path so that they can be imported directly just like in interactive mode\n","sys.path.append(os.path.abspath(\"../usr/lib/\"))\n","for script_folder in os.listdir(\"../usr/lib/\"):\n","    sys.path.append(os.path.abspath(\"../usr/lib/\"+script_folder))\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import Adam\n","from torchtext.legacy.data import Field, BucketIterator\n","from torchtext.legacy.datasets.translation import Multi30k\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from tconf import *\n","from transformer import Transformer\n","from bleuscore import idx_to_word, get_bleu"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Conditional construct depending on where the kernel is run.\n","loc = os.environ.get('KAGGLE_KERNEL_RUN_TYPE','Localhost')\n","if loc == 'Interactive' or loc == 'Localhost':\n","    conf = {\n","        'epochs': 2,\n","        'save': True\n","    }\n","# When it is run after an api push.\n","elif loc == 'Batch':\n","    !pip install -U torchtext\n","    conf = {\n","        'epochs': 100,\n","        'save': False\n","    }\n"," \n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["class DataLoader:\n","    source: Field = None\n","    targe: Field = None\n","\n","    def __init__(self, ext, tokenize_en, tokenize_de, init_token, eos_token):\n","        self.ext = ext\n","        self.tokenize_en = tokenize_en\n","        self.tokenize_de = tokenize_de\n","        self.init_token = init_token\n","        self.eos_token = eos_token\n","        print('dataset initializing start')\n","\n","    def make_dataset(self):\n","        if self.ext == ('.de', '.en'):\n","            self.source = Field(tokenize=self.tokenize_de, init_token=self.init_token, eos_token=self.eos_token,\n","                                lower=True, batch_first=True)\n","            self.target = Field(tokenize=self.tokenize_en, init_token=self.init_token, eos_token=self.eos_token,\n","                                lower=True, batch_first=True)\n","        elif self.ext == ('.en', '.de'):\n","            self.source = Field(tokenize=self.tokenize_en, init_token=self.init_token, eos_token=self.eos_token,\n","                                lower=True, batch_first=True)\n","            self.target = Field(tokenize=self.tokenize_de, init_token=self.init_token, eos_token=self.eos_token,\n","                                lower=True, batch_first=True)\n","\n","        train_data, valid_data, test_data = Multi30k.splits(exts=self.ext, fields=(self.source, self.target))\n","        return train_data, valid_data, test_data\n","\n","    def build_vocab(self, train_data, min_freq):\n","        self.source.build_vocab(train_data, min_freq=min_freq)\n","        self.target.build_vocab(train_data, min_freq=min_freq)\n","\n","    def make_iter(self, train, validate, test, batch_size, device):\n","        train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train, validate, test),\n","                                                                              batch_size=batch_size,\n","                                                                              device=device)\n","        print('dataset initializing done')\n","        return train_iterator, valid_iterator, test_iterator\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import spacy\n","\n","class Tokenizer:\n","\n","    def __init__(self):\n","        self.spacy_de = spacy.load('de')\n","        self.spacy_en = spacy.load('en')\n","\n","    def tokenize_de(self, text):\n","        \"\"\"\n","        Tokenizes German text from a string into a list of strings\n","        \"\"\"\n","        return [tok.text for tok in self.spacy_de.tokenizer(text)]\n","\n","    def tokenize_en(self, text):\n","        \"\"\"\n","        Tokenizes English text from a string into a list of strings\n","        \"\"\"\n","        return [tok.text for tok in self.spacy_en.tokenizer(text)]"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["dataset initializing start\n","dataset initializing done\n"]}],"source":["tokenizer = Tokenizer()\n","loader = DataLoader(ext=('.en', '.de'),\n","                    tokenize_en=tokenizer.tokenize_en,\n","                    tokenize_de=tokenizer.tokenize_de,\n","                    init_token='<sos>',\n","                    eos_token='<eos>')\n","\n","train, valid, test = loader.make_dataset()\n","loader.build_vocab(train_data=train, min_freq=2)\n","train_iter, valid_iter, test_iter = loader.make_iter(train, valid, test,\n","                                                     batch_size=batch_size,\n","                                                     device=device)\n","\n","src_pad_idx = loader.source.vocab.stoi['<pad>']\n","trg_pad_idx = loader.target.vocab.stoi['<pad>']\n","trg_sos_idx = loader.target.vocab.stoi['<sos>']\n","\n","enc_voc_size = len(loader.source.vocab)\n","dec_voc_size = len(loader.target.vocab)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 55,207,087 trainable parameters\n","ipykernel_launcher:7: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n"]}],"source":["\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","def initialize_weights(m):\n","    if hasattr(m, 'weight') and m.weight.dim() > 1:\n","        nn.init.kaiming_uniform(m.weight.data)\n","\n","\n","#tb = SummaryWriter()\n","model = Transformer(src_pad_idx=src_pad_idx,\n","                    trg_pad_idx=trg_pad_idx,\n","                    trg_sos_idx=trg_sos_idx,\n","                    d_model=d_model,\n","                    enc_voc_size=enc_voc_size,\n","                    dec_voc_size=dec_voc_size,\n","                    max_len=max_len,\n","                    ffn_hidden=ffn_hidden,\n","                    n_head=n_heads,\n","                    n_layers=n_layers,\n","                    drop_prob=drop_prob,\n","                    device=device).to(device)\n","\n","#tb.add_graph(model)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')\n","model.apply(initialize_weights)\n","optimizer = Adam(params=model.parameters(),\n","                 lr=init_lr,\n","                 weight_decay=weight_decay,\n","                 eps=adam_eps)\n","\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n","                                                 verbose=True,\n","                                                 factor=factor,\n","                                                 min_lr=min_lr,\n","                                                 patience=patience)\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=src_pad_idx)\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def train(model, iterator, optimizer, criterion, clip):\n","    model.train()\n","    epoch_loss = 0\n","    for i, batch in enumerate(iterator):\n","        src = batch.src\n","        trg = batch.trg\n","\n","        optimizer.zero_grad()\n","        output = model(src, trg[:, :-1])\n","        output_reshape = output.contiguous().view(-1, output.shape[-1])\n","        trg = trg[:, 1:].contiguous().view(-1)\n","\n","        loss = criterion(output_reshape, trg)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        print('step :', round((i / len(iterator)) * 100, 2), '% , loss :', loss.item())\n","\n","    return epoch_loss / len(iterator)\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def evaluate(model, iterator, criterion):\n","    model.eval()\n","    epoch_loss = 0\n","    batch_bleu = []\n","    with torch.no_grad():\n","        for i, batch in enumerate(iterator):\n","            src = batch.src\n","            trg = batch.trg\n","            output = model(src, trg[:, :-1])\n","            output_reshape = output.contiguous().view(-1, output.shape[-1])\n","            trg = trg[:, 1:].contiguous().view(-1)\n","\n","            loss = criterion(output_reshape, trg)\n","            epoch_loss += loss.item()\n","\n","            total_bleu = []\n","            for j in range(batch_size):\n","                try:\n","                    trg_words = idx_to_word(batch.trg[j], loader.target.vocab)\n","                    output_words = output[j].max(dim=1)[1]\n","                    output_words = idx_to_word(output_words, loader.target.vocab)\n","                    bleu = get_bleu(hypotheses=output_words.split(), reference=trg_words.split())\n","                    total_bleu.append(bleu)\n","                except:\n","                    pass\n","\n","            total_bleu = sum(total_bleu) / len(total_bleu)\n","            batch_bleu.append(total_bleu)\n","\n","    batch_bleu = sum(batch_bleu) / len(batch_bleu)\n","    return epoch_loss / len(iterator), batch_bleu\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def run(total_epoch, best_loss):\n","    tb = SummaryWriter()\n","    train_losses, test_losses, bleus = [], [], []\n","    for step in range(total_epoch):\n","        start_time = time.time()\n","        train_loss = train(model, train_iter, optimizer, criterion, clip)\n","        valid_loss, bleu = evaluate(model, valid_iter, criterion)\n","        end_time = time.time()\n","\n","        if step > warmup:\n","            scheduler.step(valid_loss)\n","\n","        train_losses.append(train_loss)\n","        test_losses.append(valid_loss)\n","        bleus.append(bleu)\n","        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","        if valid_loss < best_loss:\n","            best_loss = valid_loss\n","            if conf['save']:\n","                torch.save(model.state_dict(), 'results/model-{0}.pt'.format(valid_loss))\n","\n","        f = open('results/train_loss.txt', 'w')\n","        f.write(str(train_losses))\n","        f.close()\n","\n","        f = open('results/bleu.txt', 'w')\n","        f.write(str(bleus))\n","        f.close()\n","\n","        f = open('results/test_loss.txt', 'w')\n","        f.write(str(test_losses))\n","        f.close()\n","\n","        print(f'Epoch: {step + 1} | Time: {epoch_mins}m {epoch_secs}s')\n","        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","        print(f'\\tVal Loss: {valid_loss:.3f} |  Val PPL: {math.exp(valid_loss):7.3f}')\n","        print(f'\\tBLEU Score: {bleu:.3f}')\n","        tb.add_scalar(\"Train Loss\", train_loss, step)\n","        tb.add_scalar(\"Val Loss\", valid_loss, step)\n","        tb.add_scalar(\"BLEU\", bleu, step)\n","        for name, weight in model.named_parameters():\n","            tb.add_histogram(name,weight, epoch)\n","            tb.add_histogram(f'{name}.grad',weight.grad, epoch)\n","    tb.close()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["/home/pierre/git/pierre-si/transformer-hyunwoongko/usr/lib/transformer/transformer.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = self.softmax(score)\n","step : 0.0 % , loss : 10.045363426208496\n","step : 0.22 % , loss : 9.873270034790039\n","step : 0.44 % , loss : 9.95502758026123\n","step : 0.66 % , loss : 9.853436470031738\n","step : 0.88 % , loss : 9.712427139282227\n","step : 1.1 % , loss : 9.710395812988281\n","step : 1.32 % , loss : 9.656320571899414\n","step : 1.54 % , loss : 9.652429580688477\n","step : 1.76 % , loss : 9.531877517700195\n","step : 1.98 % , loss : 9.528142929077148\n","step : 2.2 % , loss : 9.531291007995605\n","step : 2.42 % , loss : 9.366520881652832\n","step : 2.64 % , loss : 9.354074478149414\n","step : 2.86 % , loss : 9.219813346862793\n","step : 3.08 % , loss : 9.313675880432129\n","step : 3.3 % , loss : 9.20814037322998\n","step : 3.52 % , loss : 9.144355773925781\n","step : 3.74 % , loss : 9.20022964477539\n","step : 3.96 % , loss : 9.033185958862305\n","step : 4.19 % , loss : 9.073776245117188\n","step : 4.41 % , loss : 8.970049858093262\n","step : 4.63 % , loss : 8.959575653076172\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-b372231ef575>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-bba42a9c8acb>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(total_epoch, best_loss)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-76a74e23cd2b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/programmes/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/programmes/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["run(conf['epochs'], inf)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3.7.8 64-bit ('base': conda)","metadata":{"interpreter":{"hash":"c875a887c8abb6fe16ed242bf424b28894bcb5ee769b5b7b2d55a08b56eb3e6d"}}}}}